{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAyM38lGUpkL"
   },
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sample Jupyter notebook is designed to demonstrate how easily analytic market data reports can be created with Monitor+. The Chart library used is Matplotlib. See the 'Imports' section below for a list of the other libraries used.\n",
    "\n",
    "The report downloads two daily market data time series. The data is requested as business days (5 day week), filled forward with a common start date. The datasets are then converted to a Pandas data frame and 6 charts displaying both daily and non daily values (defined in the 'Global Variables' section below). \n",
    "\n",
    "This report is designed to be reused so the code down to section \"Creating the Analytic Charts\" can be reused for any report that requires two datasets. You simply need to change the datasource and symbol global variables to get different datasets. You can find the datasets easily in your Monitor+ Favorites list or when viewing a datasource metadata. You can  <a href=\"https://www.sarus.com/profilemain?tab=favorites\"> click here</a> to log into your Monitor+ Favorites portal where you can manage your favorite datasets and datasources.  \n",
    "\n",
    "The Analytic method used in this sample report is a very basic QQ (Quantile-Quantile) Plot. A QQ Plot is a probability plot for comparing two probability distributions by plotting their quantiles against each other. More details on QQ Plots can be found in a web search, at the <a href=\"https://towardsdatascience.com/q-q-plots-explained-5aa8495426c0\">Towards Data Science</a> site or on <a href=\"https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot\">Wikipedia</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sObP-2EybVCt"
   },
   "source": [
    "<b>Disclaimer.</b><br>\n",
    "We offer these reports for informational purposes only and are provided ‘as is’ without warranty of any kind, either express or implied, including, but not limited to, the implied warranties of fitness for a purpose, or the warranty of non-infringement.  Please refer to our <a href=\"https://www.sarus.com/terms-and-conditions\">Terms and Conditions</a> for more information. Any links on this site are provided as a convenience and for informational purposes only; they do not constitute an endorsement or an approval by the us of any of the products, services or opinions of the corporation or organization or individual. We bear no responsibility for the accuracy, legality or content of the external site or for that of subsequent links. Contact any external sites for answers to questions regarding its content.  The market data used in the reports below may be generated sample data and as such not representative on any real or published values. Do not use any of the report values for any purpose other than to demonstrate the functionality of this report.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAyM38lGUpkL",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "aw52ArsLUbri"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'monitorplus'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#  IData is the Monitor+ class\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmonitorplus\u001b[39;00m \u001b[39mimport\u001b[39;00m IData \n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'monitorplus'"
     ]
    }
   ],
   "source": [
    "#  IData is the Monitor+ class\n",
    "from API.monitorplus import IData \n",
	"from API.monitorplus_utils import MonitorUtils\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import colorama\n",
    "import datetime\n",	
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sObP-2EybVCt"
   },
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N19Yl28DT3ky",
    "outputId": "4a9a43d8-92db-4697-c323-53ea2c700ee7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customers API Key needed to request for data from the Monitor+ API\n",
    "#  You need to  change this API key to your own one.\n",
    "API_KEY = \"VOFWM-43RCS-PUH5T-A0X8I\"\n",
    "\n",
    "# Colors  https://i.stack.imgur.com/9UVnC.png\n",
    "BOLD = '\\033[01m'\n",
    "RESET = '\\033[0m'\n",
    "BLUE_FG = '\\033[34m'\n",
    "BLACK_FG = '\\033[30m'\n",
    "GREEN_FG = '\\033[32m'\n",
    "WHITE_FG = '\\033[37m'\n",
    "\n",
    "RED_BG = '\\033[101m'\n",
    "GREEN_BG = '\\033[42m'\n",
    "# ANSI code Combinations used in labels\n",
    "WARNING =  WHITE_FG + RED_BG\n",
    "BLUE_LABEL = BOLD + BLUE_FG\n",
    "NORMAL =  GREEN_FG \n",
    "\n",
    "\n",
    "#  number of rows to list in the  table outouts\n",
    "Data_Rows=18\n",
    "\n",
    "#  The full API documentation for getting the data is at:   \n",
    "#       https://www.sarus.com/api-docs#getdatasetvaluesrc\n",
    "\n",
    "# Sample Dataset #1 to use in the Notebook\n",
    "API_Datasource1 = \"ECBFX\"\n",
    "API_DSSymbol1 = \"EURJPY\"\n",
    "# the Name below  will be filled from the API if the request is successful\n",
    "API_DSName1 = \"\"\n",
    "\n",
    "# Sample Dataset  #2 to use in the Notebook\n",
    "API_Datasource2 = \"ECBFX\"\n",
    "API_DSSymbol2 = \"EURCAD\"\n",
    "# the Name below  will be filled from the API if the request is successful\n",
    "API_DSName2 = \"\"\n",
    "\n",
    "# The earliest date to request from the API\n",
    "API_StartDate = \"2010-01-01\"\n",
    "\n",
    "# Force common start date for both series\n",
    "API_CommonStart=True\n",
    "\n",
    "#  Fill the daily data before (prefill happens before calculating monthly averages)\n",
    "API_Prefill=True\n",
    "\n",
    "# Weekends can be added or removed by setting the value to \"7\"  or \"5\"\n",
    "# \"5\" means only weekdays (no weekends) are returned. \n",
    "# Refer to th API documentation for many more options\n",
    "API_WeekType = \"5\"\n",
    "\n",
    "\n",
    "# API_PrefillType can be \"previous\",  \"midpoint\" or \"interpolate\"\n",
    "API_PrefillType = \"interpolate\"\n",
    "\n",
    "# We can choose to have 3 non-daily charts id any fqequency. \n",
    "# Valid simply Frequencies are: \n",
    "#  w, hm, m, q, hy  y \n",
    "# Check the API documentation \"Frequency Parameter\" and \"Frequency Options\" sections for examples of custom frequencies and weekend handling.\n",
    "#      https://www.sarus.com/api-docs#getdatasetvaluesrc\n",
    "\n",
    "NonDailyChartFreq = \"m\"\n",
    "NonDailyChartFreqDesc = \"monthly\"\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sObP-2EybVCt"
   },
   "source": [
    "## API - Initialisation and return values for two datasets\n",
    "\n",
    "The full list of theparameters used in the API request to get market data can be <a href=\"https://www.sarus.com/api-docs#getdatasetvaluesrc\">viewed here</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N19Yl28DT3ky",
    "outputId": "4a9a43d8-92db-4697-c323-53ea2c700ee7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialise the Python class\n",
    "idata = IData()\n",
    "# turn off comments from  Monitor+\n",
    "idata.set_verbose(False)\n",
    "\n",
    "#Store the API Key in the Python Class\n",
    "idata.set_api_key(API_KEY)\n",
    "\n",
    "# We will return the metadata for the user favorite datasets\n",
    "# Now request historical prices for two datasets in RC ( row x column) format.\n",
    "RC_DayResult = idata.get_dataset_values_rc(\n",
    "    Series=[\n",
    "        # You can change the datasources and symbols in the Global Variable section above\n",
    "        # For HandleWeekend parameters - see HandleWeekends section at the  \"Viewed Here\"  link above. 5a = 5 day adjusted.\n",
    "        {\"Datasource\": API_Datasource1,\"Symbol\": API_DSSymbol1, \"HandleWeekends\":API_WeekType,\"Fill\":True, },\n",
    "        {\"Datasource\": API_Datasource2,\"Symbol\": API_DSSymbol2, \"HandleWeekends\":API_WeekType,\"Fill\":True }\n",
    "    ],\n",
    "    # Additional API parameters\n",
    "    StartDate = API_StartDate,\n",
    "    CommonStart = API_CommonStart,\n",
    "    Frequency = \"d\",\n",
    "    Prefill = API_Prefill,\n",
    "    # For missing valuess are filled\n",
    "    FillOptions = {\"Type\": API_PrefillType},\n",
    "     )\n",
    "    \n",
    "if (RC_DayResult is None):\n",
    "       print (WARNING +'\\n The RC_Result API call returned an error. \\n' + RESET)\n",
    "else:\n",
    "    print ( NORMAL+ \" The Daily API command was run successfully. \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Display daily data in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access the Monitor+ utility file that helps us to process the report data.\n",
    "#from monitorplus_utils import MonitorUtils\n",
    "from API.monitorplus_utils import MonitorUtils\n",
    "from IPython.display import display\n",
    "RC_DayResult = None\n",
    "API_DSName1Day = \"\"\n",
    "API_DSName2Day = \"\"\n",
    "\n",
    "# Check we have data from the 'API Initialisation' section above using its RC_Result variable\n",
    "if (RC_DayResult is None):\n",
    "    print ('\\033[1m' +'\\nThe  API request for daily data failed. Please check the \"API Initialisation\" section above.' + '\\033[0m')   \n",
    "else:\n",
    "    # Extract the names for the datasets.  We can use them later to check if the extract was successful.\n",
    "    API_DSName1Day, API_DSName2Day = RC_DayResult[\"Columns\"][0]['Name'], RC_DayResult[\"Columns\"][1]['Name']\n",
    "    \n",
    "    #  Check datasets are loaded OK\n",
    "    if API_DSName2Day > \"\":\n",
    "        mu = MonitorUtils(API_DSName1Day, API_DSName2Day)\n",
    "        df = mu.get_display_data(RC_DayResult)\n",
    "        # show the latest elements in a table - rows defined in global Data_Rows variable\n",
    "        print(\"\\n\\nThe latest \"+str(Data_Rows)+\" daily data rows:\\n\")\n",
    "  \n",
    "        display(df.tail(Data_Rows))\n",
    "        \n",
    "        # The methods we use require our data to be a Time-Series. \n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "        df.set_index(\"Date\", inplace=True)   \n",
    "    else:\n",
    "        print(WARNING + '\\n Dataset number 2 was not returned from the Monitor+ Utils class. ' + RESET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Request the non-daily data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The frequency used is defined in the \"lobal Variables\" section at the top of the page  in variable  'NonDailyChartFreq'\n",
    "# set success flag\n",
    "\n",
    "\n",
    "\n",
    "# Check we have data from the 'API Initialisation' section above using its RC_Result variable\n",
    "if (RC_DayResult is None):\n",
    "    print ('\\033[1m' +'\\nThe  API request for daily data failed. Please check the \"API Initialisation\" section above.' + '\\033[0m')   \n",
    "else:\n",
    "    # Now request historical non-daily prices for two datasets in RC (row x column) format.\n",
    "    RC_NDResult = idata.get_dataset_values_rc(\n",
    "    Series=[\n",
    "\n",
    "        # You can change the datasources and symbols in the Global Variable section above\n",
    "        # For HandleWeekend parameters - see HandleWeekends section at the  \"Viewed Here\"  link above. 5a = 5 day adjusted.\n",
    "        {\"Datasource\": API_Datasource1,\"Symbol\": API_DSSymbol1, \"HandleWeekends\":API_WeekType,\"Fill\":True, },\n",
    "        {\"Datasource\": API_Datasource2,\"Symbol\": API_DSSymbol2, \"HandleWeekends\":API_WeekType,\"Fill\":True }\n",
    "         ],\n",
    "    # Additional API parameters\n",
    "    StartDate = API_StartDate,\n",
    "    Frequency = NonDailyChartFreq,\n",
    "    CommonStart = API_CommonStart,\n",
    "    Prefill = API_Prefill,\n",
    "    FillOptions = {\"Type\": API_PrefillType},\n",
    "    )\n",
    "\n",
    "if (RC_NDResult is None):\n",
    "       print (WARNING +'\\n The \"+NonDailyChartFreqDesc+\" API call returned an error. \\n' + RESET)\n",
    "else:\n",
    "    print ( NORMAL+ \" The \"+NonDailyChartFreqDesc+\" API command was run successfully. \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Display the non-daily data in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check we have data from the \"Get non-daily data\" section above using its RC_NDResult variable\n",
    "# The frequency used is defined in the \"lobal Variables\" section at the top of the page  in variable  'NonDailyChartFreq'\n",
    "# set success flag\n",
    "\n",
    "\n",
    "\n",
    "# Check we have data from the 'API Initialisation' section above using its RC_Result variable\n",
    "if (RC_DayResult is None):\n",
    "    print ('\\033[1m' +'\\nThe  API request for daily data failed. Please check the \"API Initialisation\" section above.' + '\\033[0m')   \n",
    "else:\n",
    "    # Now request historical non-daily prices for two datasets in RC (row x column) format.\n",
    "    RC_NDResult = idata.get_dataset_values_rc(\n",
    "    Series=[\n",
    "\n",
    "        # You can change the datasources and symbols in the Global Variable section above\n",
    "        # For HandleWeekend parameters - see HandleWeekends section at the  \"Viewed Here\"  link above. 5a = 5 day adjusted.\n",
    "        {\"Datasource\": API_Datasource1,\"Symbol\": API_DSSymbol1, \"HandleWeekends\":API_WeekType,\"Fill\":True, },\n",
    "        {\"Datasource\": API_Datasource2,\"Symbol\": API_DSSymbol2, \"HandleWeekends\":API_WeekType,\"Fill\":True }\n",
    "         ],\n",
    "    # Additional API parameters\n",
    "    StartDate = API_StartDate,\n",
    "    Frequency = NonDailyChartFreq,\n",
    "    CommonStart = API_CommonStart,\n",
    "    Prefill = API_Prefill,\n",
    "    FillOptions = {\"Type\": API_PrefillType},\n",
    "    )\n",
    "\n",
    "if (RC_NDResult is None):\n",
    "       print (WARNING +'\\n The \"+NonDailyChartFreqDesc+\" API call returned an error. \\n' + RESET)\n",
    "else:\n",
    "    print ( NORMAL+ \" The \"+NonDailyChartFreqDesc+\" API command was run successfully. \\n\")\n",
    "if (RC_NDResult is None):\n",
    "    print ('\\033[1m' +'\\nThe non-daily API request failed. Please check the \"Get non-daily data\" section above.' + '\\033[0m')   \n",
    "else:\n",
    "    # Extract the names for the datasets.  We can use them later to check if the extract was successful.\n",
    "    API_DSName1ND, API_DSName2ND = RC_NDResult[\"Columns\"][0]['Name'], RC_NDResult[\"Columns\"][1]['Name']\n",
    "    \n",
    "    #  Check datasets are loaded OK\n",
    "    if API_DSName2ND > \"\":\n",
    "        mu = MonitorUtils(API_DSName1ND, API_DSName2ND)\n",
    "        df_ND = mu.get_display_data(RC_NDResult)\n",
    "        print(\"\\n\\nThe latest \"+str(Data_Rows)+\" \"+NonDailyChartFreqDesc+\" data rows:\\n\")\n",
    "        # show the latest elements in a table - rows defined in global Data_Rows variable\n",
    "        display(df_ND.tail(Data_Rows))\n",
    "        \n",
    "        # The methods we use require our data to be a Time-Series. \n",
    "        df_ND[\"Date\"] = pd.to_datetime(df_ND[\"Date\"])\n",
    "        df_ND.set_index(\"Date\", inplace=True)   \n",
    "    else:\n",
    "        print(WARNING + '\\n Dataset number 2 was not returned from the Monitor+ Utils class. ' + RESET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Creating the Daily Charts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the two daily API datasets as daily charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Check datasets are loaded in case code is run out of sequence\n",
    "if API_DSName2Day > \"\":\n",
    "    df[API_DSName1Day].plot(figsize=(20,5), title = API_DSName1Day,  color = 'blue',  linewidth=.6,  label=API_DSSymbol1)\n",
    "    plt.title(f\"Daily:  {API_DSName1Day}\")\n",
    "    plt.legend(loc='upper left')\n",
    "    ax = plt.subplot()\n",
    "    ax.set_xlabel('')\n",
    "    plt.show()\n",
    " \n",
    "    df[API_DSName2Day].plot(figsize=(20,5), title = API_DSName2Day, color = 'green', linewidth=.6,   label=API_DSSymbol2)\n",
    "    plt.title(f\"Daily: {API_DSName2Day}\")\n",
    "    plt.legend(loc='upper left')\n",
    "    ax = plt.subplot()\n",
    "    ax.set_xlabel('')\n",
    "    plt.show()\n",
    "    \n",
    "    # We normalize the datasets to a common range to show them overlaid. We use the \"mean\" to calculate the average\n",
    "    df[API_DSName1Day].div(df[API_DSName1Day].mean()).plot(figsize=(20,5), title = API_DSName1Day, color = 'blue',linewidth=.6, label=API_DSSymbol1)\n",
    "    df[API_DSName2Day].div(df[API_DSName2Day].mean()).plot(figsize=(20,5), title = API_DSName2Day,  linestyle = 'solid', color = 'green',linewidth=.6, label=API_DSSymbol2)\n",
    "    plt.title(\"Both Series\")\n",
    "    plt.title(f\" Normalized Daily:  {API_DSSymbol1}  and  {API_DSSymbol2}\")\n",
    "    plt.legend(loc='upper left')\n",
    "    ax = plt.subplot()\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('NORMAILZED RANGE')    \n",
    "    plt.show()    \n",
    "    print( BLUE_LABEL + '\\n\\nCreating the '+NonDailyChartFreqDesc+' average charts. ' + RESET)\n",
    "else:\n",
    "    print(WARNING + '\\n\\n Daily Chart: No dataset was loaded from the API for series number 2. ' + RESET)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Creating the non-daily Charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Check datasets are loaded\n",
    "\n",
    "\n",
    "if (API_DSName2Day > \"\")  and (RC_NDResult is not None):\n",
    "    df_ND[API_DSName1ND].div(df_ND[API_DSName1ND].mean()).plot(figsize=(22,5), title = API_DSName1ND, marker = '*', color = 'blue', markerfacecolor = 'r', linewidth=.8,   label=API_DSSymbol1)\n",
    "    plt.title(f\"{NonDailyChartFreqDesc.upper()}: {API_DSName1ND} \")\n",
    "    plt.legend(loc='upper left')\n",
    "    ax = plt.subplot()\n",
    "    ax.set_xlabel('')\n",
    "    plt.show()    \n",
    "    \n",
    "    df_ND[API_DSName2ND].div(df_ND[API_DSName2ND].mean()).plot(figsize=(22,5), title = API_DSName2ND, marker = '*', color = 'green', markerfacecolor = 'b', linewidth=.8, label=API_DSSymbol2)\n",
    "    plt.title(f\"{NonDailyChartFreqDesc.upper()}: {API_DSName2ND}\")\n",
    "    plt.legend(loc='upper left')\n",
    "    ax = plt.subplot()\n",
    "    ax.set_xlabel('')\n",
    "    plt.show()    \n",
    "    \n",
    "    df_ND[API_DSName1ND].div(df_ND[API_DSName1ND].mean()).plot(figsize=(22,5), title = API_DSName1ND,marker = '*', color = 'blue', markerfacecolor = 'r', linewidth=.8,   label=API_DSSymbol1)\n",
    "    df_ND[API_DSName2ND].div(df_ND[API_DSName2ND].mean()).plot(figsize=(22,5), title = API_DSName2ND,marker = '*', color = 'green', markerfacecolor = 'b', linewidth=.8, label=API_DSSymbol2)\n",
    "    plt.title(f\":Normalized {NonDailyChartFreqDesc.upper()}: {API_DSSymbol1}  and  {API_DSSymbol2}\")\n",
    "    plt.legend(loc='upper left')\n",
    "    ax = plt.subplot()\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('NORMAILZED RANGE')\n",
    "    plt.show() \n",
    "else:\n",
    "    print(WARNING + '\\n'+NonDailyChartFreqDesc.upper()+' Charts: Non-daily data is not available for series #2 ('+API_DSName2Day+').' + RESET)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forescating with SARIMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import plotly.graph_objs as go\n",
    "from  plotly.offline import plot\n",
    "import chart_studio.plotly as py\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot,iplot\n",
    "init_notebook_mode(connected='true')\n",
    "df[API_DSName1Day].iplot(title=\"Daily Data Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from  plotly.offline import plot\n",
    "import chart_studio.plotly as py\n",
    "from chart_studio.plotly import plot_mpl\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot,iplot\n",
    "init_notebook_mode(connected='true')\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "result = seasonal_decompose(df[API_DSName1Day], model='multiplicative')\n",
    "fig = result.plot()\n",
    "#plot_mpl(fig)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing the SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyramid.arima import auto_arima; the pyramid namespace is deprecated and has migrated to pmdarima\n",
    "from pmdarima import auto_arima\n",
    "stepwise_model = auto_arima(df[API_DSName1Day], start_p=1, start_q=1,\n",
    "                           max_p=3, max_q=3, m=12,\n",
    "                           start_P=0, seasonal=True,\n",
    "                           d=1, D=1, trace=True,\n",
    "                           error_action='ignore',  \n",
    "                           suppress_warnings=True, \n",
    "                           stepwise=True)\n",
    "print(stepwise_model.aic())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[API_DSName1Day].loc['2010-01-01':'2019-12-01']\n",
    "test = df[API_DSName1Day].loc['2020-01-01':]\n",
    "#test.reset_index(drop=True, inplace=True)\n",
    "print(test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_forecast = stepwise_model.predict(n_periods=test.shape[0], dynamic=True)\n",
    "# This returns an array of predictions:\n",
    "print(future_forecast.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_forecast = pd.DataFrame(future_forecast, index = test.index, columns=['Prediction'])\n",
    "#future_forecast.reset_index(drop=True, inplace=True)\n",
    "#future_forecast.shape\n",
    "#future_forecast\n",
    "#test.shape\n",
    "#test, future_forecast\n",
    "df1 = pd.concat([test, future_forecast], axis=1)\n",
    "df1.iplot()\n",
    "#future_forecast.iplot()\n",
    "#test.iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df[API_DSName1Day], future_forecast], axis=1).iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "LAyM38lGUpkL",
    "sObP-2EybVCt",
    "Y1DLRL3DDRqS",
    "0HlOzC9ADcnm",
    "Rn28ilWLbMeh",
    "SmlOeZpZdMOr",
    "ImmEw5v7X_fw",
    "hPqT_IYcS0c4"
   ],
   "name": "Don_G.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "05cb10757a915ba4f0b2d61d98f17ca1a378878ad6df931e006b0b27723673f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

